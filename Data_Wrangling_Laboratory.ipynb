{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2NsXPIEcquHrOylBY9gCW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Handling Missing Values: Identify and fill missing values in a dataset using methods such as mean imputation or forward/backward filling."
      ],
      "metadata": {
        "id": "YJDpKnNdMBhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "from numpy import nan\n",
        "# Sample dataset with missing values\n",
        "data = {\n",
        "    'A': [1, 2, nan, 4, 5],\n",
        "    'B': [nan, 2, 3, nan, 5],\n",
        "    'C': [1, nan, 3, 4, nan]\n",
        "}\n",
        "# Create a DataFrame\n",
        "df = DataFrame(data)\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Mean Imputation\n",
        "df_mean_imputed = df.fillna(df.mean())\n",
        "\n",
        "# Display the DataFrame after Mean Imputation\n",
        "print(\"\\nDataFrame after Mean Imputation:\")\n",
        "print(df_mean_imputed)\n",
        "#Forward Filling\n",
        "#This program fills missing values with the previous value in the column.\n",
        "# Sample dataset with missing values\n",
        "data = {\n",
        "    'A': [1, 2, nan, 4, 5],\n",
        "    'B': [nan, 2, 3, nan, 5],\n",
        "    'C': [1, nan, 3, 4, nan]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = DataFrame(data)\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Forward Filling\n",
        "df_forward_filled = df.fillna(method='ffill')\n",
        "\n",
        "# Display the DataFrame after Forward Filling\n",
        "print(\"\\nDataFrame after Forward Filling:\")\n",
        "print(df_forward_filled)\n",
        "#Backward Filling\n",
        "#This program fills missing values with the next value in the column.\n",
        "\n",
        "# Sample dataset with missing values\n",
        "data = {\n",
        "    'A': [1, 2, nan, 4, 5],\n",
        "    'B': [nan, 2, 3, nan, 5],\n",
        "    'C': [1, nan, 3, 4, nan]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = DataFrame(data)\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Backward Filling\n",
        "df_backward_filled = df.fillna(method='bfill')\n",
        "\n",
        "# Display the DataFrame after Backward Filling\n",
        "print(\"\\nDataFrame after Backward Filling:\")\n",
        "print(df_backward_filled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV2q3_u1MBL2",
        "outputId": "9f0a3bcd-6279-43a8-a323-070165453a32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "     A    B    C\n",
            "0  1.0  NaN  1.0\n",
            "1  2.0  2.0  NaN\n",
            "2  NaN  3.0  3.0\n",
            "3  4.0  NaN  4.0\n",
            "4  5.0  5.0  NaN\n",
            "\n",
            "DataFrame after Mean Imputation:\n",
            "     A         B         C\n",
            "0  1.0  3.333333  1.000000\n",
            "1  2.0  2.000000  2.666667\n",
            "2  3.0  3.000000  3.000000\n",
            "3  4.0  3.333333  4.000000\n",
            "4  5.0  5.000000  2.666667\n",
            "Original DataFrame:\n",
            "     A    B    C\n",
            "0  1.0  NaN  1.0\n",
            "1  2.0  2.0  NaN\n",
            "2  NaN  3.0  3.0\n",
            "3  4.0  NaN  4.0\n",
            "4  5.0  5.0  NaN\n",
            "\n",
            "DataFrame after Forward Filling:\n",
            "     A    B    C\n",
            "0  1.0  NaN  1.0\n",
            "1  2.0  2.0  1.0\n",
            "2  2.0  3.0  3.0\n",
            "3  4.0  3.0  4.0\n",
            "4  5.0  5.0  4.0\n",
            "Original DataFrame:\n",
            "     A    B    C\n",
            "0  1.0  NaN  1.0\n",
            "1  2.0  2.0  NaN\n",
            "2  NaN  3.0  3.0\n",
            "3  4.0  NaN  4.0\n",
            "4  5.0  5.0  NaN\n",
            "\n",
            "DataFrame after Backward Filling:\n",
            "     A    B    C\n",
            "0  1.0  2.0  1.0\n",
            "1  2.0  2.0  3.0\n",
            "2  4.0  3.0  3.0\n",
            "3  4.0  5.0  4.0\n",
            "4  5.0  5.0  NaN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-8d0185ed729b>:39: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_forward_filled = df.fillna(method='ffill')\n",
            "<ipython-input-2-8d0185ed729b>:62: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_backward_filled = df.fillna(method='bfill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Data Filtering: Filter rows or columns based on specified criteria, such as removing outliers or selecting data within a certain range."
      ],
      "metadata": {
        "id": "uWyJPeZ5Mu9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "data={\n",
        "    'Name':['Alice','Bob','Charlie','David','Eva'],\n",
        "    'Score':[85,92,78,88,90],\n",
        "    'Age':[20, 21, 19, 22, 20]\n",
        "}\n",
        "df=DataFrame(data)\n",
        "filtered_df=df[df['Score']>=80]\n",
        "print(filtered_df)\n",
        "data={\n",
        "    'Name':['Alice','Bob','Charlie','David','Eva'],\n",
        "    'Score':[85,92,78,88,150],\n",
        "    'Age':[20, 21, 19, 22, 20]\n",
        "}\n",
        "df=DataFrame(data)\n",
        "\n",
        "# Define the range to keep scores within\n",
        "lower_bound = 70\n",
        "upper_bound = 100\n",
        "\n",
        "# Filter the rows based on the score range\n",
        "filtered_df = df[(df['Score'] >= lower_bound) & (df['Score'] <= upper_bound)]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "print(filtered_df)\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Score': [85, 92, 78, 88, 150],\n",
        "    'Age': [20, 21, 19, 22, 20],\n",
        "    'Gender': ['F', 'M', 'M', 'M', 'F']\n",
        "}\n",
        "df = DataFrame(data)\n",
        "selected_columns_df=df[['Name','Score']]\n",
        "print(selected_columns_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iLZAlN8MuOQ",
        "outputId": "ed51a5d6-de43-4b36-cb0f-1dc19981a435"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Name  Score  Age\n",
            "0  Alice     85   20\n",
            "1    Bob     92   21\n",
            "3  David     88   22\n",
            "4    Eva     90   20\n",
            "      Name  Score  Age\n",
            "0    Alice     85   20\n",
            "1      Bob     92   21\n",
            "2  Charlie     78   19\n",
            "3    David     88   22\n",
            "      Name  Score\n",
            "0    Alice     85\n",
            "1      Bob     92\n",
            "2  Charlie     78\n",
            "3    David     88\n",
            "4      Eva    150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Data Aggregation: Aggregate data by grouping rows based on a specific attribute and computing summary statistics, such as mean, median, or count."
      ],
      "metadata": {
        "id": "S1V8sSSlPowV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'C', 'A', 'C', 'B'],\n",
        "    'Value': [10, 20, 15, 25, 30, 10, 40, 25]\n",
        "}\n",
        "df = DataFrame(data)\n",
        "mean_data = df.groupby('Category')['Value'].mean().reset_index()\n",
        "# Display the result of groupby 'Category' and computed mean\n",
        "print(mean_data)\n",
        "median_data = df.groupby('Category')['Value'].median().reset_index()\n",
        "# Display the result of groupby 'Category' and computed median\n",
        "print(median_data)\n",
        "count_data = df.groupby('Category')['Value'].count().reset_index()\n",
        "# Display the result of groupby 'Category' and computed count\n",
        "print(count_data)\n",
        "aggregated_data = df.groupby('Category').agg(\n",
        "    mean_value = ('Value', 'mean'),\n",
        "    median_value = ('Value', 'median'),\n",
        "    count = ('Value', 'count')\n",
        ").reset_index()\n",
        "# Display result of groupby 'Category' and summary statistics\n",
        "print(aggregated_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C428Qr9mPn3t",
        "outputId": "ba223733-9ad9-46d9-f5ea-52f7ffedfed7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category      Value\n",
            "0        A  11.666667\n",
            "1        B  23.333333\n",
            "2        C  35.000000\n",
            "  Category  Value\n",
            "0        A   10.0\n",
            "1        B   25.0\n",
            "2        C   35.0\n",
            "  Category  Value\n",
            "0        A      3\n",
            "1        B      3\n",
            "2        C      2\n",
            "  Category  mean_value  median_value  count\n",
            "0        A   11.666667          10.0      3\n",
            "1        B   23.333333          25.0      3\n",
            "2        C   35.000000          35.0      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Data Concatenation: Concatenate multiple datasets along rows or columns to create a unified dataset."
      ],
      "metadata": {
        "id": "-PfCVoxrNPXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame, concat\n",
        "\n",
        "# Sample dataframes\n",
        "df1 = DataFrame({\n",
        "    'ID': [1, 2, 3],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie']\n",
        "})\n",
        "print(df1,\"\\n\")\n",
        "df2 = DataFrame({\n",
        "    'ID': [4, 5, 6],\n",
        "    'Name': ['David', 'Eve', 'Frank']\n",
        "})\n",
        "print(df2,\"\\n\")\n",
        "df3 = DataFrame({\n",
        "    'ID': [7, 8, 9],\n",
        "    'Name': ['Grace', 'Heidi', 'Ivan']\n",
        "})\n",
        "print(df3,\"\\n\")\n",
        "# Concatenating along rows (adding more rows to the dataset)\n",
        "df_row_concat = concat([df1, df2, df3], axis=0, ignore_index=True)\n",
        "print(\"Concatenated along rows:\\n\", df_row_concat)\n",
        "\n",
        "# Sample dataframes with different columns\n",
        "df4 = DataFrame({\n",
        "    'Age': [25, 30, 35]\n",
        "})\n",
        "print(df4,\"\\n\")\n",
        "# Concatenating along columns (adding more columns to the dataset)\n",
        "df_col_concat = concat([df1, df4], axis=1)\n",
        "print(\"\\nConcatenated along columns:\\n\", df_col_concat)\n",
        "print(concat([df1, df4], join='inner'))\n",
        "print(concat([df1, df4], join='outer'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBRHzeKtNO_a",
        "outputId": "6ef6ceb1-3860-4bbf-cebb-cd1d66bc852f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID     Name\n",
            "0   1    Alice\n",
            "1   2      Bob\n",
            "2   3  Charlie \n",
            "\n",
            "   ID   Name\n",
            "0   4  David\n",
            "1   5    Eve\n",
            "2   6  Frank \n",
            "\n",
            "   ID   Name\n",
            "0   7  Grace\n",
            "1   8  Heidi\n",
            "2   9   Ivan \n",
            "\n",
            "Concatenated along rows:\n",
            "    ID     Name\n",
            "0   1    Alice\n",
            "1   2      Bob\n",
            "2   3  Charlie\n",
            "3   4    David\n",
            "4   5      Eve\n",
            "5   6    Frank\n",
            "6   7    Grace\n",
            "7   8    Heidi\n",
            "8   9     Ivan\n",
            "   Age\n",
            "0   25\n",
            "1   30\n",
            "2   35 \n",
            "\n",
            "\n",
            "Concatenated along columns:\n",
            "    ID     Name  Age\n",
            "0   1    Alice   25\n",
            "1   2      Bob   30\n",
            "2   3  Charlie   35\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: [0, 1, 2, 0, 1, 2]\n",
            "    ID     Name   Age\n",
            "0  1.0    Alice   NaN\n",
            "1  2.0      Bob   NaN\n",
            "2  3.0  Charlie   NaN\n",
            "0  NaN      NaN  25.0\n",
            "1  NaN      NaN  30.0\n",
            "2  NaN      NaN  35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Data Reshaping: Reshape data by pivoting, stacking, or unstacking to convert between wide and long formats"
      ],
      "metadata": {
        "id": "h2raKrf3NlsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Name': ['John', 'Mary', 'John', 'Mary'],\n",
        "    'Year': [2020, 2020, 2021, 2021],\n",
        "    'Sales': [100, 200, 150, 250]\n",
        "}\n",
        "\n",
        "df = DataFrame(data)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(df)\n",
        "\n",
        "# Pivot (long to wide)\n",
        "df_pivot = df.pivot(index='Name', columns='Year', values='Sales')\n",
        "\n",
        "print(\"\\nPivoted Data:\")\n",
        "print(df_pivot)\n",
        "\n",
        "# Stack (wide to long)\n",
        "df_stack = df_pivot.stack()\n",
        "\n",
        "print(\"\\nStacked Data:\")\n",
        "print(df_stack)\n",
        "\n",
        "# Unstack (long to wide)\n",
        "df_unstack = df_stack.unstack()\n",
        "\n",
        "print(\"\\nUnstacked Data:\")\n",
        "print(df_unstack)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmmeKkViNlbr",
        "outputId": "66f7ccc2-9297-4444-dba2-0ebbdcc56a77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "   Name  Year  Sales\n",
            "0  John  2020    100\n",
            "1  Mary  2020    200\n",
            "2  John  2021    150\n",
            "3  Mary  2021    250\n",
            "\n",
            "Pivoted Data:\n",
            "Year  2020  2021\n",
            "Name            \n",
            "John   100   150\n",
            "Mary   200   250\n",
            "\n",
            "Stacked Data:\n",
            "Name  Year\n",
            "John  2020    100\n",
            "      2021    150\n",
            "Mary  2020    200\n",
            "      2021    250\n",
            "dtype: int64\n",
            "\n",
            "Unstacked Data:\n",
            "Year  2020  2021\n",
            "Name            \n",
            "John   100   150\n",
            "Mary   200   250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Data Sampling: Randomly sample rows or columns from a dataset to create a smaller subset for analysis"
      ],
      "metadata": {
        "id": "WNM-mtMxOF4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'name': ['John', 'Jane', 'Tom', 'Anna', 'James'],\n",
        "    'age': [23, 25, 24, 22, 26],\n",
        "    'score': [88, 92, 85, 90, 87]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Randomly sample 3 rows from the dataset\n",
        "df_sample_rows = df.sample(n=3, random_state=1)\n",
        "print(df_sample_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJj8yrIdOE0G",
        "outputId": "4ad53ae6-ad89-4cc7-9ed7-0ffd231bd0f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name  age  score\n",
            "2    Tom   24     85\n",
            "1   Jane   25     92\n",
            "4  James   26     87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) Data Conversion: Convert data types of columns, such as converting categorical variables to numerical or vice versa"
      ],
      "metadata": {
        "id": "H8OBvWdeOQ_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame, get_dummies, cut\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'name': ['John', 'Jane', 'Tom', 'Anna'],\n",
        "    'gender': ['male', 'female', 'male', 'female']\n",
        "}\n",
        "\n",
        "df = DataFrame(data)\n",
        "\n",
        "# Convert categorical 'gender' column to numerical using one-hot encoding\n",
        "df_one_hot = get_dummies(df, columns=['gender'])\n",
        "print(df_one_hot)\n",
        "\n",
        "\n",
        "# Convert categorical 'gender' column to numerical using label encoding\n",
        "le = LabelEncoder()\n",
        "df['gender_encoded'] = le.fit_transform(df['gender'])\n",
        "print(df)\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'name': ['John', 'Jane', 'Tom', 'Anna'],\n",
        "    'age': [23, 25, 24, 22]\n",
        "}\n",
        "\n",
        "df = DataFrame(data)\n",
        "\n",
        "# Define bins and labels for age\n",
        "bins = [20, 22, 24, 26]\n",
        "labels = ['Young', 'Mid', 'Senior']\n",
        "\n",
        "# Convert numerical 'age' column to categorical using pd.cut()\n",
        "df['age_group'] = cut(df['age'], bins=bins, labels=labels)\n",
        "print(df)\n",
        "\n",
        "# Convert numerical 'age' column to string\n",
        "df['age_str'] = df['age'].astype(str)\n",
        "print(df)\n",
        "\n",
        "# Convert a string column to integer (if applicable)\n",
        "df['age'] = df['age_str'].astype(int)\n",
        "print(df)\n",
        "\n",
        "# Sample dataset with boolean values\n",
        "data = {\n",
        "    'name': ['John', 'Jane', 'Tom', 'Anna'],\n",
        "    'is_active': [True, False, True, False]\n",
        "}\n",
        "\n",
        "df = DataFrame(data)\n",
        "\n",
        "# Convert boolean 'is_active' column to integers (0 or 1)\n",
        "df['is_active_int'] = df['is_active'].astype(int)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i1gFI9GOQlN",
        "outputId": "3b4f8814-9cb1-412f-ea59-a0ec2f5c3121"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   name  gender_female  gender_male\n",
            "0  John          False         True\n",
            "1  Jane           True        False\n",
            "2   Tom          False         True\n",
            "3  Anna           True        False\n",
            "   name  gender  gender_encoded\n",
            "0  John    male               1\n",
            "1  Jane  female               0\n",
            "2   Tom    male               1\n",
            "3  Anna  female               0\n",
            "   name  age age_group\n",
            "0  John   23       Mid\n",
            "1  Jane   25    Senior\n",
            "2   Tom   24       Mid\n",
            "3  Anna   22     Young\n",
            "   name  age age_group age_str\n",
            "0  John   23       Mid      23\n",
            "1  Jane   25    Senior      25\n",
            "2   Tom   24       Mid      24\n",
            "3  Anna   22     Young      22\n",
            "   name  age age_group age_str\n",
            "0  John   23       Mid      23\n",
            "1  Jane   25    Senior      25\n",
            "2   Tom   24       Mid      24\n",
            "3  Anna   22     Young      22\n",
            "   name  is_active  is_active_int\n",
            "0  John       True              1\n",
            "1  Jane      False              0\n",
            "2   Tom       True              1\n",
            "3  Anna      False              0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) Text Data Processing: Clean and preprocess text data by removing punctuation, stopwords, and performing tokenization"
      ],
      "metadata": {
        "id": "x9-1W9UEOXrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import download\n",
        "from re import sub\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK data (only needed once)\n",
        "download('punkt')\n",
        "download('stopwords')\n",
        "download('punkt_tab')\n",
        "\n",
        "# Sample text\n",
        "text = \"Data wrangling is the process of transforming raw data into a usable format for analysis. It's also known as data munging, data blending, or data remediation\"\n",
        "\n",
        "# 1. Convert to lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# 2. Remove punctuation using regex\n",
        "text = sub(r'[^\\w\\s]', '', text)  # Keep only words and spaces\n",
        "\n",
        "# 3. Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# 4. Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Result\n",
        "print(\"Filtered Tokens:\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_BmSdTVOXRl",
        "outputId": "4b7d1981-5369-4ae2-d663-ab8630bf7aab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens: ['data', 'wrangling', 'process', 'transforming', 'raw', 'data', 'usable', 'format', 'analysis', 'also', 'known', 'data', 'munging', 'data', 'blending', 'data', 'remediation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9) Date-Time Processing: Extract date or time components from datetime columns and perform operations such as calculating time differences or aggregating by time intervals."
      ],
      "metadata": {
        "id": "uQG6OS11Hx76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy-hyLdkGuWS",
        "outputId": "9978bece-f16e-410a-9945-a1f5a39be6c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Frame:\n",
            "              datetime  Number of People  year  month  day  hour  minute\n",
            "0 2023-11-01 10:00:00                 2  2023     11    1    10       0\n",
            "1 2023-11-01 12:30:00                 4  2023     11    1    12      30\n",
            "2 2023-11-02 15:45:00                 3  2023     11    2    15      45\n",
            "Time differences calculated:\n",
            "              datetime  Number of People  year  month  day  hour  minute  \\\n",
            "0 2023-11-01 10:00:00                 2  2023     11    1    10       0   \n",
            "1 2023-11-01 12:30:00                 4  2023     11    1    12      30   \n",
            "2 2023-11-02 15:45:00                 3  2023     11    2    15      45   \n",
            "\n",
            "             end_time time_difference  time_diff_hours  time_diff_minutes  \n",
            "0 2023-11-01 13:00:00 0 days 03:00:00              3.0              180.0  \n",
            "1 2023-11-01 15:30:00 0 days 03:00:00              3.0              180.0  \n",
            "2 2023-11-02 18:45:00 0 days 03:00:00              3.0              180.0  \n",
            "            Number of People  year  month  day  hour  minute  time_diff_hours  \\\n",
            "datetime                                                                        \n",
            "2023-11-01                 6  4046     22    2    22      30              6.0   \n",
            "2023-11-02                 3  2023     11    2    15      45              3.0   \n",
            "\n",
            "            time_diff_minutes  \n",
            "datetime                       \n",
            "2023-11-01              360.0  \n",
            "2023-11-02              180.0  \n",
            "            Number of People\n",
            "datetime                    \n",
            "2023-11-01                 6\n",
            "2023-11-02                 3\n",
            "Daily Summary:\n",
            "             Number of People\n",
            "datetime                    \n",
            "2023-11-01                 6\n",
            "2023-11-02                 3\n",
            "3-Hour Summary:\n",
            "                      Number of People    year  month  day  hour  minute  \\\n",
            "datetime                                                                  \n",
            "2023-11-01 09:00:00               2.0  2023.0   11.0  1.0  10.0     0.0   \n",
            "2023-11-01 12:00:00               4.0  2023.0   11.0  1.0  12.0    30.0   \n",
            "2023-11-01 15:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-01 18:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-01 21:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-02 00:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-02 03:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-02 06:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-02 09:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-02 12:00:00               NaN     NaN    NaN  NaN   NaN     NaN   \n",
            "2023-11-02 15:00:00               3.0  2023.0   11.0  2.0  15.0    45.0   \n",
            "\n",
            "                               end_time time_difference  time_diff_hours  \\\n",
            "datetime                                                                   \n",
            "2023-11-01 09:00:00 2023-11-01 13:00:00 0 days 03:00:00              3.0   \n",
            "2023-11-01 12:00:00 2023-11-01 15:30:00 0 days 03:00:00              3.0   \n",
            "2023-11-01 15:00:00                 NaT             NaT              NaN   \n",
            "2023-11-01 18:00:00                 NaT             NaT              NaN   \n",
            "2023-11-01 21:00:00                 NaT             NaT              NaN   \n",
            "2023-11-02 00:00:00                 NaT             NaT              NaN   \n",
            "2023-11-02 03:00:00                 NaT             NaT              NaN   \n",
            "2023-11-02 06:00:00                 NaT             NaT              NaN   \n",
            "2023-11-02 09:00:00                 NaT             NaT              NaN   \n",
            "2023-11-02 12:00:00                 NaT             NaT              NaN   \n",
            "2023-11-02 15:00:00 2023-11-02 18:45:00 0 days 03:00:00              3.0   \n",
            "\n",
            "                     time_diff_minutes  \n",
            "datetime                                \n",
            "2023-11-01 09:00:00              180.0  \n",
            "2023-11-01 12:00:00              180.0  \n",
            "2023-11-01 15:00:00                NaN  \n",
            "2023-11-01 18:00:00                NaN  \n",
            "2023-11-01 21:00:00                NaN  \n",
            "2023-11-02 00:00:00                NaN  \n",
            "2023-11-02 03:00:00                NaN  \n",
            "2023-11-02 06:00:00                NaN  \n",
            "2023-11-02 09:00:00                NaN  \n",
            "2023-11-02 12:00:00                NaN  \n",
            "2023-11-02 15:00:00              180.0  \n",
            "Changing Timezones:\n",
            "                      Number of People  year  month  day  hour  minute  \\\n",
            "datetime                                                                \n",
            "2023-11-01 10:00:00                 2  2023     11    1    10       0   \n",
            "2023-11-01 12:30:00                 4  2023     11    1    12      30   \n",
            "2023-11-02 15:45:00                 3  2023     11    2    15      45   \n",
            "\n",
            "                               end_time time_difference  time_diff_hours  \\\n",
            "datetime                                                                   \n",
            "2023-11-01 10:00:00 2023-11-01 13:00:00 0 days 03:00:00              3.0   \n",
            "2023-11-01 12:30:00 2023-11-01 15:30:00 0 days 03:00:00              3.0   \n",
            "2023-11-02 15:45:00 2023-11-02 18:45:00 0 days 03:00:00              3.0   \n",
            "\n",
            "                     time_diff_minutes                  datetime  \n",
            "datetime                                                          \n",
            "2023-11-01 10:00:00              180.0 2023-11-01 06:00:00-04:00  \n",
            "2023-11-01 12:30:00              180.0 2023-11-01 08:30:00-04:00  \n",
            "2023-11-02 15:45:00              180.0 2023-11-02 11:45:00-04:00  \n"
          ]
        }
      ],
      "source": [
        "from pandas import DataFrame, to_datetime, Timedelta\n",
        "\n",
        "# Sample DataFrame with datetime column\n",
        "df = DataFrame({\n",
        "    'datetime': to_datetime(['2023-11-01 10:00:00', '2023-11-01 12:30:00', '2023-11-02 15:45:00']),\n",
        "    'Number of People': [2, 4, 3]\n",
        "})\n",
        "\n",
        "# Extract date components\n",
        "df['year'] = df['datetime'].dt.year\n",
        "df['month'] = df['datetime'].dt.month\n",
        "df['day'] = df['datetime'].dt.day\n",
        "\n",
        "# Extract time components\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['minute'] = df['datetime'].dt.minute\n",
        "\n",
        "# View the result\n",
        "print(\"Data Frame:\\n\",df)\n",
        "\n",
        "# Adding another datetime column for demonstration\n",
        "df['end_time'] = df['datetime'] + Timedelta(hours=3)\n",
        "\n",
        "# Calculate the time difference\n",
        "df['time_difference'] = df['end_time'] - df['datetime']\n",
        "\n",
        "# Convert time difference to hours, minutes, etc.\n",
        "df['time_diff_hours'] = df['time_difference'] / Timedelta(hours=1)\n",
        "df['time_diff_minutes'] = df['time_difference'] / Timedelta(minutes=1)\n",
        "\n",
        "print('Time differences calculated:\\n',df)\n",
        "\n",
        "# Set the datetime column as index\n",
        "df.set_index('datetime', inplace=True)\n",
        "\n",
        "# Resample by day and calculate the sum or any other aggregate function Select only numeric columns\n",
        "daily_summary = df.resample('D').sum(numeric_only=True)\n",
        "print(daily_summary)\n",
        "\n",
        "# Aggregating with min and max for datetime columns\n",
        "daily_summary = df.resample('D').agg({\n",
        "    'Number of People': 'sum'  # Example of summing a numeric column\n",
        "})\n",
        "print(daily_summary)\n",
        "\n",
        "# Resample by custom interval, e.g., 3 hours\n",
        "three_hour_summary = df.resample('3h').min()\n",
        "\n",
        "print(\"Daily Summary:\\n\", daily_summary)\n",
        "print(\"3-Hour Summary:\\n\", three_hour_summary)\n",
        "\n",
        "# Set timezone\n",
        "df['datetime'] = df.index.to_series().dt.tz_localize('UTC')\n",
        "\n",
        "# Convert to another timezone\n",
        "df['datetime'] = df['datetime'].dt.tz_convert('America/New_York')\n",
        "\n",
        "print(\"Changing Timezones:\\n\",df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10) Data Merging: Merge two or more datasets based on common keys or indices to combine information from different sources."
      ],
      "metadata": {
        "id": "ltLzB_7YcdcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame, merge\n",
        "# Sample DataFrame 1\n",
        "df1 = DataFrame({\n",
        "    'id': [1, 2, 3, 4],\n",
        "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'age': [24, 27, 22, 32]\n",
        "})\n",
        "# Sample DataFrame 2\n",
        "df2 = DataFrame({\n",
        "    'id': [3, 4, 5, 6],\n",
        "    'name': ['Charlie', 'David', 'Eve', 'Frank'],\n",
        "    'salary': [70000, 80000, 90000, 85000]\n",
        "})\n",
        "inner_join = merge(df1, df2, on='id', how='inner')\n",
        "print(\"Inner Join:\\n\", inner_join)\n",
        "left_join = merge(df1, df2, on='id', how='left')\n",
        "print('Left Join:\\n', left_join)\n",
        "right_join = merge(df1, df2, on='id', how='right')\n",
        "print(\"Right join:\\n\", right_join)\n",
        "outer_join = merge(df1, df2, on='id', how='outer')\n",
        "print(\"Outer Join:\\n\", outer_join)\n",
        "multi_key_merge = merge(df1, df2, on=['id', 'name'], how='inner')\n",
        "print('Merged using Multiple keys:\\n', multi_key_merge)\n",
        "# Set id as the index for demonstration\n",
        "df1.set_index('id', inplace=True)\n",
        "df2.set_index('id', inplace=True)\n",
        "index_merge = merge(df1, df2, left_index=True, right_index=True, how='inner')\n",
        "print(\"Merged using Index:\\n\", index_merge)\n",
        "# Reset indices for original merge example\n",
        "df1.reset_index(inplace=True)\n",
        "df2.reset_index(inplace=True)\n",
        "suffix_merge = merge(df1, df2, on='id', how='outer', suffixes=('_left', '_right'))\n",
        "print(\"Handling Suffixes of overlapping columns:\", suffix_merge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AzwPMpXcgD3",
        "outputId": "b075d7bf-1737-4661-ec80-feaffe03262a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner Join:\n",
            "    id   name_x  age   name_y  salary\n",
            "0   3  Charlie   22  Charlie   70000\n",
            "1   4    David   32    David   80000\n",
            "Left Join:\n",
            "    id   name_x  age   name_y   salary\n",
            "0   1    Alice   24      NaN      NaN\n",
            "1   2      Bob   27      NaN      NaN\n",
            "2   3  Charlie   22  Charlie  70000.0\n",
            "3   4    David   32    David  80000.0\n",
            "Right join:\n",
            "    id   name_x   age   name_y  salary\n",
            "0   3  Charlie  22.0  Charlie   70000\n",
            "1   4    David  32.0    David   80000\n",
            "2   5      NaN   NaN      Eve   90000\n",
            "3   6      NaN   NaN    Frank   85000\n",
            "Outer Join:\n",
            "    id   name_x   age   name_y   salary\n",
            "0   1    Alice  24.0      NaN      NaN\n",
            "1   2      Bob  27.0      NaN      NaN\n",
            "2   3  Charlie  22.0  Charlie  70000.0\n",
            "3   4    David  32.0    David  80000.0\n",
            "4   5      NaN   NaN      Eve  90000.0\n",
            "5   6      NaN   NaN    Frank  85000.0\n",
            "Merged using Multiple keys:\n",
            "    id     name  age  salary\n",
            "0   3  Charlie   22   70000\n",
            "1   4    David   32   80000\n",
            "Merged using Index:\n",
            "      name_x  age   name_y  salary\n",
            "id                               \n",
            "3   Charlie   22  Charlie   70000\n",
            "4     David   32    David   80000\n",
            "Handling Suffixes of overlapping columns:    id name_left   age name_right   salary\n",
            "0   1     Alice  24.0        NaN      NaN\n",
            "1   2       Bob  27.0        NaN      NaN\n",
            "2   3   Charlie  22.0    Charlie  70000.0\n",
            "3   4     David  32.0      David  80000.0\n",
            "4   5       NaN   NaN        Eve  90000.0\n",
            "5   6       NaN   NaN      Frank  85000.0\n"
          ]
        }
      ]
    }
  ]
}